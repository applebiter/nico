{
  "3": {
    "inputs": {
      "seed": 187282968,
      "steps": 26,
      "cfg": 8.0,
      "sampler_name": "dpmpp_3m_sde_gpu",
      "scheduler": "exponential",
      "denoise": 1,
      "model": [
        "40",
        0
      ],
      "positive": [
        "37",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "5": {
    "inputs": {
      "width": 1344,
      "height": 768,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": "The Apprentice walks across the countryside and need fear no man as long as there are animals nearby. It's the Fae whom she hopes most to meet on her long walks through the valley. Animals will often accompany her on her walks.",
      "clip": [
        "40",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "text, watermark, blurry, low quality",
      "clip": [
        "40",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "40",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "style_transfer",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "13": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "39",
        0
      ],
      "image": [
        "34",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "19": {
    "inputs": {
      "strength": 0.75,
      "noise_augmentation": 0,
      "conditioning": [
        "6",
        0
      ],
      "clip_vision_output": [
        "13",
        0
      ]
    },
    "class_type": "unCLIPConditioning",
    "_meta": {
      "title": "unCLIPConditioning"
    }
  },
  "34": {
    "inputs": {
      "image": "/home/sysadmin/Programs/ComfyUI/output/z-image_00024_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "36": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "39",
        0
      ],
      "image": [
        "38",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "37": {
    "inputs": {
      "strength": 0.75,
      "noise_augmentation": 0,
      "conditioning": [
        "19",
        0
      ],
      "clip_vision_output": [
        "36",
        0
      ]
    },
    "class_type": "unCLIPConditioning",
    "_meta": {
      "title": "unCLIPConditioning"
    }
  },
  "38": {
    "inputs": {
      "image": "/usr/share/backgrounds/ubuntustudio/2404_BanaueCMSW.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "39": {
    "inputs": {
      "clip_name": "clip_vision_g.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "40": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  }
}